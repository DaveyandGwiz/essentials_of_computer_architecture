REVIEW OF ESSENTIAL TERMS
AND CONCEPTS
1. What is the function of a CPU?
Fetch and decode instructions.
 The main task of the Central Processing Unit (CPU) is to retrieve program instructions, understand and decipher them and perform the indicated sequence of operations on the correct data.

• The CPU is divided into datapath and control unit.

2. What purpose does a datapath serve?
The datapath is basically an intricate interconnection of arithmetic and logic units (ALU) and storage units which are connected by buses whose timings of data transfer are controlled by the CPU clock.

3. What does the control unit do?
The control unit oversees the chronological ordering of operations and makes sure that the appropriate data are at the right place at the right time.

4. Where are registers located, and what are the different types?
Registers are located in the CPU. Registers have types of general-purpose and specialized.
An example of a special purpose regiters, for example in mIPS architecture, is $zero which is hardwired to yield a value of zero.

5. How does the ALU know which function to perform?
The ALU relies on control signals generated by the Control Unit, based on the opcode of the current instruction. These signals tell the ALU which operation to perform, ensuring that the correct computation or logic function is executed.

6. Why is a bus often a communications bottleneck?

A bus can become a communications bottleneck because:
    Shared Medium: All devices connected to the bus must share the same communication channel, limiting the number of simultaneous transfers.
    Limited Bandwidth: The bus has a fixed bandwidth, which can be insufficient for high-speed or high-volume data transfers in modern systems.
    Contention: Multiple devices may compete to use the bus, causing delays as devices wait for access.
    Latency: The time taken to arbitrate and transfer data on the bus can slow overall system performance.

7. What is the difference between a point-to-point bus and a multipoint bus?

Point-to-Point Bus:
    A dedicated connection between two devices.
    Provides higher bandwidth and avoids contention.
    Example: Connections between a CPU and GPU via PCIe.

Multipoint Bus:
    Shared by multiple devices.
    More cost-effective and simpler but introduces contention and potential delays.
    Example: Traditional system buses like the PCI bus.

8. Why is a bus protocol important?
A bus protocol defines the rules for communication on a bus, ensuring orderly and efficient data transfer. It is important because:

    Coordination: Ensures that devices communicate without conflicts, especially on multipoint buses.
    Data Integrity: Specifies how data is sent, received, and acknowledged to avoid corruption.
    Timing: Provides rules for synchronization, ensuring devices operate correctly at different speeds.
    Device Compatibility: Ensures that devices from different manufacturers can interoperate on the same bus.

9. Explain the differences between data buses, address buses, and control buses.

Data Bus:
    Carries actual data being transferred between components.
    Bi-directional, as data can move to or from the CPU.
    Example: Transferring an instruction from memory to the CPU.
Address Bus:
    Carries the memory or I/O addresses to specify the location for data read/write.
    Uni-directional, as the CPU typically generates the addresses.
    Example: Sending a memory address to RAM to fetch data.
Control Bus:
    Carries control signals to manage and coordinate data transfer.
    Signals include read/write operations, interrupts, and clock pulses.
    Example: Telling a device to start or stop a transfer.

10. What is a bus cycle?
A bus cycle refers to the sequence of steps required to transfer data or instructions across a bus. It typically includes:
    Address Phase: The CPU places the memory or I/O address on the address bus.
    Control Phase: Control signals indicate the type of operation (e.g., read or write).
    Data Phase: The actual data is transferred on the data bus.
    The speed of bus cycles affects the overall performance of the system. Faster bus cycles mean quicker communication between components.

11. Name three different types of buses and where you would find them.
12. What is the difference between synchronous buses and
nonsynchronous buses?

13. What are the four types of bus arbitration?
Bus arbitration determines which device gains control of the bus in a multipoint system when multiple devices request access simultaneously. The four types are:

Centralized Arbitration:
    A single arbiter (usually part of the CPU or a separate device) decides which device gets access.
    Example: PCI bus.

Distributed Arbitration:
    All devices participate in the arbitration process and communicate directly to resolve conflicts.
    Example: Ethernet using collision detection.

Priority-Based Arbitration:
    Devices are assigned priorities, and higher-priority devices gain access first.
    Example: Used in systems where certain devices (e.g., interrupts) require faster responses.

Round-Robin Arbitration:
    Access is granted in a rotating order to ensure fairness among devices.
    Example: Found in some multiprocessor systems to balance load.
    Each arbitration method balances trade-offs between fairness, performance, and complexity.

14. Explain the difference between clock cycles and clock frequency.
Duration of a single tick of the system. It is the smallest unit of the system in which operations can be performed.
The frequency of the clock, or the clock frequency, is the number of clock cycles per second.

15. Difference Between System Clocks and Bus Clocks
System Clock:
    The system clock regulates the CPU and other core components, ensuring that instructions and processes execute in sync.
    Operates at a high frequency (e.g., 3 GHz for modern CPUs) to match the speed of the processor.
Bus Clock:
    The bus clock governs the timing of data transfers on the system bus, which connects the CPU, memory, and peripherals.
    Typically runs at a lower frequency than the system clock to match the slower speeds of external devices.
    Some modern systems use a multiplier to link the bus clock to the system clock (e.g., a 200 MHz bus clock with a 15x multiplier gives a 3 GHz system clock).

16. What is the function of an I/O interface?
The function of an I/O interface is to act as a bridge between the CPU/memory and external input/output devices. It facilitates:
    Data Transfer: Manages the exchange of data between the CPU and I/O devices.
    Signal Conversion: Translates signals between the CPU’s digital format and the device’s native format.
    Synchronization: Resolves timing differences between the high-speed CPU and slower I/O devices.
    Control and Monitoring: Handles control signals to manage device operations and monitors the status of devices.
    Interrupt Handling: Coordinates the CPU’s response to interrupts generated by I/O devices.

17. Explain the difference between memory-mapped I/O and instructionbased I/O.
    Memory-Mapped I/O: The CPU treats I/O devices like memory, using memory instructions to interact with them.
    Instruction-Based I/O: The CPU uses dedicated I/O instructions for communication with I/O devices.


18. What is the difference between a byte and a word? What distinguishes
each?
A byte is 8 bits. A word is a size dependent on a given architecutre. It is the size of an instruction in the system. 
It's size varies from 8 all the way to 64 or more which is common.

19. Explain the difference between byte addressable and word
addressable.
In a byte addressable system, each byte in memory has a unique address, while in word addressable memory only every word has an address 
where a word is the size of an instruction in memory. Most systems are byte addressabel which requires that more bits in each
 instruction be used for the address.

20. Why is address alignment important?

Address alignment means data's adress is a mutiple of its data size ie
a 4 byte integer should be stored at an address divisble by 4 as this allows for
faster access and simplifies design.

21. List and explain the two types of memory interleaving and the
differences between them.
Data interweaving allows separate memory banks to form a complete set of memory addresses.
Two types of interweaving include low and high orders.
In high order interweaving, the final bits of the instruction correspond to the address where the adress
will consist of an adress for the module (bank) and an offset which denotes a location within that bank.

22. Describe how an interrupt works, and name four different types.

An iterrupt is a process which allows a CPU to pause its current execution flow to respond to another event.
Types of interrupts include:
Hardware, software, traps (errors during executution), timer interrupts.

23. How does a maskable interrupt differ from a nonmaskable interrupt?
Maskable events are lower priority interrupts which can be disabled.
Unmaskable events cannot be ignored, hence, it is processed immediately.

24. Why is it that if MARIE has 4K words of main memory, addresses
must have 12 bits?
4K=4 * 2^10 = 2^12  implies 4,096 words of memory
Hence, to address each location in memory, 12 bits must be reserved for identifying the address.

25. Explain the functions of all of MARIE’s registers.
Accumulator (AC):
    The primary working register for arithmetic and logic operations.
    Stores intermediate results of calculations.
Memory Address Register (MAR)
    Holds the address of the memory location to be accessed (for reading or writing).
Memory Buffer Register (MBR)
    Temporarily holds data being transferred between the CPU and memory.
Program Counter (PC)
    Keeps track of the address of the next instruction to be executed.
Instruction Register (IR)
    Holds the current instruction being executed.
Input Register (IN)
    Temporarily stores input data entered into the system.


26. What is an opcode?
An opcode (operation code) is a string of bits that uniquely identifies a specific instruction in the Instruction Set Architecture (ISA) of a processor.

27. Explain how each instruction in MARIE works.
Instruction Set
------------------
Load X:	Load the value from memory into AC	Fetches the value at address X and stores it in the Accumulator (AC).
Store X:	Store the value in AC into memory	Writes the value in the AC to memory address X.
Add X:	Add the value from memory to AC	Adds the value at address X to the AC.
Subt X:	Subtract the value from memory from AC	Subtracts the value at address X from the AC.
Input:	Get input from the user	Reads a value from the Input Register (IN) into the AC.
Output:	Send value to the output device	Writes the value in the AC to the Output Register (OUT).
Halt:	Stop program execution	Terminates the program.
Skipcond:	Skip the next instruction based on a condition	Skips the next instruction if the condition specified in the instruction is met.
Jump X:	Jump to a specific address	Sets the Program Counter (PC) to X, altering the flow of execution.


28. How does a machine language differ from an assembly language? Is
the conversion one-to-one (one assembly instruction equals one
machine instruction)?
Yes. Machine language is a series of binary values a processor can read directly while an 
assembly language is human readable.
Assemblers convert assembly code into machine language.

29. What is the significance of RTN?
Register transfer notation shows how at the register level values are moved or altered and the flow of data
between registers.

30. Is a microoperation the same thing as a machine instruction?
A microoperation is a low-level operation that specifies an elementary action on data, such as transferring data between registers or performing an arithmetic operation.
It is a building block for executing machine instructions.

Example: For the machine instruction ADD R1, R2, R3, the corresponding microoperations might be:
Fetch the value from R2 into a temporary register.
Fetch the value from R3 into the ALU.
Perform the addition in the ALU.
Store the result in R1.



31. How does a microoperation differ from a regular assembly language
instruction?

A microoperation represents the individual steps a CPU performs to execute an instruction, such as transferring data between registers or performing an arithmetic operation.

In contrast, an assembly language instruction corresponds to a higher-level operation defined in the Instruction Set Architecture (ISA), such as ADD or LOAD.

32. Explain the steps of the fetch–decode–execute cycle.
Fetch: CPU obtains an instruction from memory.
Decode: CPU decodes the instruction to be ran, this can include interpriting the raw bits of an opcode
to understand the inscruction to be performed and obtaing values (operands) to be used.
Execute: The CPU performs the instruction and may yield a output.


33. How does interrupt-driven I/O work?

Interrupt-driven I/O is a mechanism that allows the CPU to handle input/output (I/O) operations efficiently by using interrupts instead of continuously checking the status of I/O devices (polling).


34. Explain how an assembler works, including how it generates the
symbol table, what it does with source and object code, and how it
handles labels.

An assembler is a program that converts assembly language code (human-readable mnemonics) into machine language (binary code) that the CPU can execute. The process involves several key steps, including managing labels and generating the symbol table.

The symbol table is a data structure that maps labels and symbolic names to their corresponding memory addresses or values.
Example: START: LOAD X
The label START is added to the symbol table with the address of the LOAD X instruction.

35. What is an embedded system? How does it differ from a regular
computer?

An embedded system is a specialized computer system designed to perform a specific task or set of tasks, often within a larger system. It integrates hardware and software to control or monitor devices.

36. Provide a trace (similar to the one in Figure 4.14) for Example 4.1.

The instruction is A -B

here is 5 - 3 using a subroutine

Load A   // load first number into A   
store x  // use X as a parameter to the 1st number
load B
store Y
JNS SUBRT  // store return address and jump to procedure
Load X 
output
Halt
X Dec 0
Y Dec 0
A dec 5
B dec 3
SUBRT Hex 0 // store return address here
    load X // load first number into AC
    subt Y // sutract Y from AC
    JUMPI SUBRT
    END 
// The system knows the address for A because the assembler assigns memory locations to all variables and 
//instructions during the assembly process. 

37. Explain the difference between hardwired control and
microprogrammed control.

Hardwired Control:
    Uses fixed logic circuits to generate control signals.
    Fast but inflexible; changes require hardware redesign.
Microprogrammed Control:
    Uses a microprogram stored in control memory to generate control signals.
    Flexible but slower; updates require modifying the microprogram.

38. What is a stack? Why is it important for programming?
A stack is a Last In, First Out (LIFO) data structure where the most recently added entry is the first to be accessed or removed. Stacks support two primary operations:

Stacks ensure a defined order of data and restrict access to only the topmost entry, making them essential for processes like function calls, where only the most recent data (e.g., return addresses, local variables) is relevant.

 39. Compare CISC machines to RISC machines.

CISC (Complex Instruction Set Computing):
    ISA: Complex with many specialized instructions.
    Execution: Single instructions often execute multi-step operations (e.g., MULT may load, multiply, and store in one instruction).
    Hardware: Requires more transistors for decoding and execution.
    Performance: Optimized for minimizing memory usage and reducing program size.
    Example: Intel x86.
RISC (Reduced Instruction Set Computing):
    ISA: Simple and streamlined with fewer instructions.
    Execution: Each instruction performs a single operation (e.g., load, store, add) and executes in one clock cycle.
    Hardware: Simpler, enabling faster execution and easier pipelining.
    Performance: Optimized for speed, power efficiency, and pipelining.
    Example: ARM architecture.

 40. How does Intel’s architecture differ from MIPS?

 Feature	        Intel Architecture	                        MIPS Architecture
ISA Type	        CISC (Complex Instruction Set Computing)	RISC (Reduced Instruction Set Computing)
Instruction         Length	Variable-length instructions	    Fixed-length instructions (typically 32 bits)
Execution	        Complex instructions; some take multiple cycles	Simple instructions; most take one cycle
Registers	        Smaller register set (e.g., x86 has 8 general-purpose registers)	Larger register set (e.g., 32 in MIPS)
Addressing Modes	Many addressing modes	Fewer addressing modes
Pipeline	        Harder to implement due to instruction complexity	Easier due to simplicity
Power Efficiency	Less efficient	                            More power-efficient
Usage	            Found in PCs, servers, and laptops	        Common in embedded systems and low-power devices


 41. Name four Intel processors and four MIPS processors.
Intel Processors:
    Intel 8086: First 16-bit processor, introduced in 1978.
    Intel Core i7: High-performance consumer processor.
    Intel Xeon: Designed for servers and data centers.
    Intel Pentium: Popular processor series in the 1990s and 2000s.
MIPS Processors:
    R2000: Early MIPS RISC processor, used in workstations.
    R3000: Improved version of the R2000, used in systems like the Sony PlayStation.
    MIPS32: 32-bit RISC processor for embedded systems.
    MIPS64: 64-bit version, designed for high-performance computing and networking devices.







